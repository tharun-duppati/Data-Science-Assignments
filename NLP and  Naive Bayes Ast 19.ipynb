{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f736c343-0146-4f4a-9360-933d9d10f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5803f7-87cd-4860-aa13-8b945273cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tharu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tharu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tharu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure necessary NLTK data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22360e84-0285-4275-9107-71e8a3670cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.religion....</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.origins:4...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu talk.religion....</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu sci.skeptic:43...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Data              Labels\n",
       "0     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...         alt.atheism\n",
       "1     Newsgroups: alt.atheism\\nPath: cantaloupe.srv....         alt.atheism\n",
       "2     Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...         alt.atheism\n",
       "3     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...         alt.atheism\n",
       "4     Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...         alt.atheism\n",
       "...                                                 ...                 ...\n",
       "1995  Xref: cantaloupe.srv.cs.cmu.edu talk.abortion:...  talk.religion.misc\n",
       "1996  Xref: cantaloupe.srv.cs.cmu.edu talk.religion....  talk.religion.misc\n",
       "1997  Xref: cantaloupe.srv.cs.cmu.edu talk.origins:4...  talk.religion.misc\n",
       "1998  Xref: cantaloupe.srv.cs.cmu.edu talk.religion....  talk.religion.misc\n",
       "1999  Xref: cantaloupe.srv.cs.cmu.edu sci.skeptic:43...  talk.religion.misc\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load Dataset\n",
    "data = pd.read_csv(\"D:\\\\ExcelR Assignments\\\\Assignment 19\\\\blogs.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75696e4a-8296-4948-a263-67531b5ee3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5586e68f-d44e-40be-bae3-4fb2eefb4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Extraction\n",
    "def extract_features(data, column):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data[column])\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bbed2d-b30d-4d8d-8029-b51e9e5462d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train-Test Split\n",
    "def split_data(features, labels, test_size=0.2, random_state=42):\n",
    "    return train_test_split(features, labels, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05063a94-6bb2-4c97-9a0d-7a4378d94473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train Naive Bayes Model\n",
    "def train_model(X_train, y_train):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a3e604-223c-4bd9-8536-720c4111966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate Model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "728182b9-feb1-453d-ba2b-bc6966613fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Sentiment Analysis\n",
    "def perform_sentiment_analysis(data, text_column):\n",
    "    sentiments = []\n",
    "    for text in data[text_column]:\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            sentiments.append('Positive')\n",
    "        elif polarity < 0:\n",
    "            sentiments.append('Negative')\n",
    "        else:\n",
    "            sentiments.append('Neutral')\n",
    "    data['Sentiment'] = sentiments\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2b4c3f2-9ede-4ea7-8d9d-2c5fd306d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.55      0.94      0.69        18\n",
      "           comp.graphics       0.80      0.89      0.84        18\n",
      " comp.os.ms-windows.misc       0.87      0.91      0.89        22\n",
      "comp.sys.ibm.pc.hardware       0.88      0.84      0.86        25\n",
      "   comp.sys.mac.hardware       0.79      0.90      0.84        21\n",
      "          comp.windows.x       1.00      0.76      0.86        25\n",
      "            misc.forsale       1.00      0.67      0.80        18\n",
      "               rec.autos       0.94      0.94      0.94        18\n",
      "         rec.motorcycles       0.83      0.94      0.88        16\n",
      "      rec.sport.baseball       0.74      0.94      0.83        18\n",
      "        rec.sport.hockey       0.88      1.00      0.94        15\n",
      "               sci.crypt       0.86      1.00      0.93        19\n",
      "         sci.electronics       0.76      0.81      0.79        16\n",
      "                 sci.med       0.94      0.88      0.91        17\n",
      "               sci.space       1.00      0.86      0.92        21\n",
      "  soc.religion.christian       0.85      0.96      0.90        23\n",
      "      talk.politics.guns       0.96      0.79      0.86        28\n",
      "   talk.politics.mideast       1.00      0.95      0.97        20\n",
      "      talk.politics.misc       0.71      0.94      0.81        18\n",
      "      talk.religion.misc       0.83      0.21      0.33        24\n",
      "\n",
      "                accuracy                           0.84       400\n",
      "               macro avg       0.86      0.86      0.84       400\n",
      "            weighted avg       0.87      0.84      0.84       400\n",
      "\n",
      "Accuracy: 0.845\n",
      "Precision: 0.8658760249638503\n",
      "Recall: 0.845\n",
      "F1-Score: 0.8359663649041836\n",
      "Sentiment Distribution:\n",
      " Sentiment                 Negative  Positive\n",
      "Labels                                      \n",
      "alt.atheism                     23        77\n",
      "comp.graphics                   24        76\n",
      "comp.os.ms-windows.misc         22        78\n",
      "comp.sys.ibm.pc.hardware        20        80\n",
      "comp.sys.mac.hardware           24        76\n",
      "comp.windows.x                  27        73\n",
      "misc.forsale                    16        84\n",
      "rec.autos                       17        83\n",
      "rec.motorcycles                 26        74\n",
      "rec.sport.baseball              29        71\n",
      "rec.sport.hockey                34        66\n",
      "sci.crypt                       19        81\n",
      "sci.electronics                 19        81\n",
      "sci.med                         29        71\n",
      "sci.space                       27        73\n",
      "soc.religion.christian          13        87\n",
      "talk.politics.guns              30        70\n",
      "talk.politics.mideast           22        78\n",
      "talk.politics.misc              22        78\n",
      "talk.religion.misc              14        86\n"
     ]
    }
   ],
   "source": [
    "# Main Execution\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(\"D:\\\\ExcelR Assignments\\\\Assignment 19\\\\blogs.csv\")\n",
    "\n",
    "    # Preprocess the text data\n",
    "    data['Cleaned_Data'] = data['Data'].apply(preprocess_text)\n",
    "\n",
    "    # Extract features and labels\n",
    "    X, vectorizer = extract_features(data, 'Cleaned_Data')\n",
    "    y = data['Labels']\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\")\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    data = perform_sentiment_analysis(data, 'Data')\n",
    "\n",
    "    # Analyze sentiment distribution\n",
    "    sentiment_distribution = data.groupby(['Labels', 'Sentiment']).size().unstack(fill_value=0)\n",
    "    print(\"Sentiment Distribution:\\n\", sentiment_distribution)\n",
    "\n",
    "    # Save the results\n",
    "    data.to_csv('blogs_with_sentiments.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d3fdb-bdd7-4ea2-a9bd-ac320a7cfd82",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392aedad-c82b-4c1a-bc6e-7bb30b7d749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Naive Bayes Classification:\n",
    "The Multinomial Naive Bayes model successfully categorized the blog posts based on their text content.\n",
    "The model's evaluation metrics (accuracy, precision, recall, and F1-score) indicate its effectiveness in handling this classification task.\n",
    "The classification report provided detailed insights into the model's performance across all categories, highlighting areas of strength \n",
    "and potential improvement.\n",
    "\n",
    "Sentiment Analysis:\n",
    "Sentiment analysis categorized the blog posts into positive, negative, and neutral sentiments.\n",
    "The distribution of sentiments across different blog categories revealed trends, which could provide insights into the tone and emotional content \n",
    "of the posts in each category.\n",
    "These findings can be leveraged to understand audience engagement and thematic sentiment trends.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
