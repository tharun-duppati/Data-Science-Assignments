{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Qu3gFkdnrUUx",
        "outputId": "0041a5a7-dc1f-43b3-c4ed-7cfa7e515cdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
              "0          T     2     8      3       5      1     8    13      0      6   \n",
              "1          I     5    12      3       7      2    10     5      5      4   \n",
              "2          D     4    11      6       8      6    10     6      2      6   \n",
              "3          N     7    11      6       6      3     5     9      4      6   \n",
              "4          G     2     1      3       1      1     8     6      6      6   \n",
              "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
              "19995      D     2     2      3       3      2     7     7      7      6   \n",
              "19996      C     7    10      8       8      4     4     8      6      9   \n",
              "19997      T     6     9      6       7      5     6    11      3      7   \n",
              "19998      S     2     3      4       2      1     8     7      2      6   \n",
              "19999      A     4     9      6       6      2     9     5      3      1   \n",
              "\n",
              "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
              "0          6      10       8      0       8      0       8  \n",
              "1         13       3       9      2       8      4      10  \n",
              "2         10       3       7      3       7      3       9  \n",
              "3          4       4      10      6      10      2       8  \n",
              "4          6       5       9      1       7      5      10  \n",
              "...      ...     ...     ...    ...     ...    ...     ...  \n",
              "19995      6       6       4      2       8      3       7  \n",
              "19996     12       9      13      2       9      3       7  \n",
              "19997     11       9       5      2      12      2       4  \n",
              "19998     10       6       8      1       9      5       8  \n",
              "19999      8       1       8      2       7      2       8  \n",
              "\n",
              "[20000 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eafd08ae-6d83-4db2-a96c-e3b1deee1936\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>xbox</th>\n",
              "      <th>ybox</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>onpix</th>\n",
              "      <th>xbar</th>\n",
              "      <th>ybar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybar</th>\n",
              "      <th>xy2bar</th>\n",
              "      <th>xedge</th>\n",
              "      <th>xedgey</th>\n",
              "      <th>yedge</th>\n",
              "      <th>yedgex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>T</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eafd08ae-6d83-4db2-a96c-e3b1deee1936')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eafd08ae-6d83-4db2-a96c-e3b1deee1936 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eafd08ae-6d83-4db2-a96c-e3b1deee1936');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e18342d1-c1ca-4641-adae-1d50c8238ac7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e18342d1-c1ca-4641-adae-1d50c8238ac7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e18342d1-c1ca-4641-adae-1d50c8238ac7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2efe4eae-2764-4160-9c7e-0d1c928818d0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2efe4eae-2764-4160-9c7e-0d1c928818d0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"letter\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"J\",\n          \"W\",\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          2,\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          12,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3,\n          6,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          5,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"onpix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6,\n          13,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          10,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xy2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          2,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedgey\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          7,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0,\n          4,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedgex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          8,\n          10,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Alphabets_data.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the dataset\n",
        "print(\"Number of samples:\", len(data))\n",
        "print(\"Number of features:\", len(data.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NF-I60WsOXX",
        "outputId": "ceb0621a-8997-4a39-db01-498429995944"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20000\n",
            "Number of features: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Alphabets_data.csv')\n",
        "\n",
        "# Handling missing values (replace with mean)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numerical_cols = data.select_dtypes(include=['number']).columns\n",
        "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Data normalization (using MinMaxScaler)\n",
        "scaler = MinMaxScaler()\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Label Encoding for the letter column\n",
        "label_encoder = LabelEncoder()\n",
        "data['letter'] = label_encoder.fit_transform(data['letter'])\n",
        "\n",
        "# Display the preprocessed data\n",
        "data\n",
        "# Summarize the dataset\n",
        "print(\"Number of samples:\", len(data))\n",
        "print(\"Number of features:\", len(data.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIXEcdncsfHT",
        "outputId": "a4c38801-ea59-437c-f245-62ae6f0b2625"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20000\n",
            "Number of features: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8prIy2fMtALV",
        "outputId": "9ae0e6fa-d205-40d8-9ec9-257cab800bac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       letter      xbox      ybox     width    height     onpix      xbar  \\\n",
              "0          19  0.133333  0.533333  0.200000  0.333333  0.066667  0.533333   \n",
              "1           8  0.333333  0.800000  0.200000  0.466667  0.133333  0.666667   \n",
              "2           3  0.266667  0.733333  0.400000  0.533333  0.400000  0.666667   \n",
              "3          13  0.466667  0.733333  0.400000  0.400000  0.200000  0.333333   \n",
              "4           6  0.133333  0.066667  0.200000  0.066667  0.066667  0.533333   \n",
              "...       ...       ...       ...       ...       ...       ...       ...   \n",
              "19995       3  0.133333  0.133333  0.200000  0.200000  0.133333  0.466667   \n",
              "19996       2  0.466667  0.666667  0.533333  0.533333  0.266667  0.266667   \n",
              "19997      19  0.400000  0.600000  0.400000  0.466667  0.333333  0.400000   \n",
              "19998      18  0.133333  0.200000  0.266667  0.133333  0.066667  0.533333   \n",
              "19999       0  0.266667  0.600000  0.400000  0.400000  0.133333  0.600000   \n",
              "\n",
              "           ybar     x2bar     y2bar     xybar    x2ybar    xy2bar     xedge  \\\n",
              "0      0.866667  0.000000  0.400000  0.400000  0.666667  0.533333  0.000000   \n",
              "1      0.333333  0.333333  0.266667  0.866667  0.200000  0.600000  0.133333   \n",
              "2      0.400000  0.133333  0.400000  0.666667  0.200000  0.466667  0.200000   \n",
              "3      0.600000  0.266667  0.400000  0.266667  0.266667  0.666667  0.400000   \n",
              "4      0.400000  0.400000  0.400000  0.400000  0.333333  0.600000  0.066667   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "19995  0.466667  0.466667  0.400000  0.400000  0.400000  0.266667  0.133333   \n",
              "19996  0.533333  0.400000  0.600000  0.800000  0.600000  0.866667  0.133333   \n",
              "19997  0.733333  0.200000  0.466667  0.733333  0.600000  0.333333  0.133333   \n",
              "19998  0.466667  0.133333  0.400000  0.666667  0.400000  0.533333  0.066667   \n",
              "19999  0.333333  0.200000  0.066667  0.533333  0.066667  0.533333  0.133333   \n",
              "\n",
              "         xedgey     yedge    yedgex  \n",
              "0      0.533333  0.000000  0.533333  \n",
              "1      0.533333  0.266667  0.666667  \n",
              "2      0.466667  0.200000  0.600000  \n",
              "3      0.666667  0.133333  0.533333  \n",
              "4      0.466667  0.333333  0.666667  \n",
              "...         ...       ...       ...  \n",
              "19995  0.533333  0.200000  0.466667  \n",
              "19996  0.600000  0.200000  0.466667  \n",
              "19997  0.800000  0.133333  0.266667  \n",
              "19998  0.600000  0.333333  0.533333  \n",
              "19999  0.466667  0.133333  0.533333  \n",
              "\n",
              "[20000 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47a30db7-e968-45ba-8d77-a8b7f462b3f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>xbox</th>\n",
              "      <th>ybox</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>onpix</th>\n",
              "      <th>xbar</th>\n",
              "      <th>ybar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybar</th>\n",
              "      <th>xy2bar</th>\n",
              "      <th>xedge</th>\n",
              "      <th>xedgey</th>\n",
              "      <th>yedge</th>\n",
              "      <th>yedgex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>3</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>2</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>19</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>18</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47a30db7-e968-45ba-8d77-a8b7f462b3f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47a30db7-e968-45ba-8d77-a8b7f462b3f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47a30db7-e968-45ba-8d77-a8b7f462b3f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b9b3b9c-c193-4708-9f71-d2596e80b06f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b9b3b9c-c193-4708-9f71-d2596e80b06f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b9b3b9c-c193-4708-9f71-d2596e80b06f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3f322c75-6f60-4ce3-ace4-0dff9e0fbed1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f322c75-6f60-4ce3-ace4-0dff9e0fbed1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"letter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          9,\n          22,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1275474363420439,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.13333333333333333,\n          0.3333333333333333,\n          0.7333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybox\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22030368690401558,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5333333333333333,\n          0.8,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1343048853711412,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.2,\n          0.4,\n          0.5333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15075936222020023,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.3333333333333333,\n          0.4666666666666667,\n          0.26666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"onpix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14603052470529984,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.06666666666666667,\n          0.13333333333333333,\n          0.4666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xbar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13506902730700768,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5333333333333333,\n          0.6666666666666666,\n          0.4666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15502358474343633,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.8666666666666667,\n          0.3333333333333333,\n          0.4666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17999785839870813,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.0,\n          0.3333333333333333,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1587215254376078,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.4,\n          0.26666666666666666,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16589832793841183,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.4,\n          0.8666666666666667,\n          0.4666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2ybar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1754046765689342,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.6666666666666666,\n          0.2,\n          0.13333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xy2bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1387079337436533,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5333333333333333,\n          0.6,\n          0.7333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15550272348226205,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.0,\n          0.13333333333333333,\n          0.5333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xedgey\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1031148290879783,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5333333333333333,\n          0.4666666666666667,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17113816939759877,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.0,\n          0.26666666666666666,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yedgex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10783133682786761,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.5333333333333333,\n          0.6666666666666666,\n          0.7333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Assuming 'data' DataFrame is already prepared as in the previous code\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))  # Input layer and first hidden layer\n",
        "model.add(Dense(32, activation='relu'))  # Second hidden layer\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer (number of classes)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ol3NYqEJuyV0",
        "outputId": "e23c49b3-3fdb-478c-a9a7-8b8dc2c1fef5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │             \u001b[38;5;34m858\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,026\u001b[0m (15.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,026</span> (15.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,026\u001b[0m (15.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,026</span> (15.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the dataset into training and test sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% train, 20% test\n",
        "\n",
        "# Now you can use X_train, X_test, y_train, and y_test for training and evaluating your model\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnQeXFX7vBlx",
        "outputId": "b140635f-c5c7-4d05-8265-957c7bf4e3c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (16000, 16)\n",
            "X_test shape: (4000, 16)\n",
            "y_train shape: (16000,)\n",
            "y_test shape: (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1) # Adjust epochs and batch size as needed\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1) # Convert probabilities to class labels\n",
        "\n",
        "# Now y_pred_classes contains the predicted classes for the test set\n",
        "y_pred_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7d6-Ly8vYWk",
        "outputId": "cede1b16-b7e8-4a43-bc19-b038c1e58a07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1778 - loss: 3.0241 - val_accuracy: 0.4338 - val_loss: 1.9911\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4822 - loss: 1.8365 - val_accuracy: 0.5625 - val_loss: 1.5491\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5752 - loss: 1.5070 - val_accuracy: 0.5987 - val_loss: 1.3902\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 1.3384 - val_accuracy: 0.6256 - val_loss: 1.3131\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6454 - loss: 1.2524 - val_accuracy: 0.6650 - val_loss: 1.2198\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - loss: 1.1843 - val_accuracy: 0.6856 - val_loss: 1.1622\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 1.1081 - val_accuracy: 0.7175 - val_loss: 1.0679\n",
            "Epoch 8/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 1.0463 - val_accuracy: 0.7244 - val_loss: 1.0167\n",
            "Epoch 9/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 1.0013 - val_accuracy: 0.7400 - val_loss: 0.9616\n",
            "Epoch 10/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.9368 - val_accuracy: 0.7581 - val_loss: 0.9132\n",
            "Epoch 11/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.9146 - val_accuracy: 0.7606 - val_loss: 0.8943\n",
            "Epoch 12/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.8670 - val_accuracy: 0.7688 - val_loss: 0.8524\n",
            "Epoch 13/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.8370 - val_accuracy: 0.7713 - val_loss: 0.8579\n",
            "Epoch 14/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 0.7972 - val_accuracy: 0.7875 - val_loss: 0.8165\n",
            "Epoch 15/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.7934 - val_accuracy: 0.7856 - val_loss: 0.7948\n",
            "Epoch 16/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.7604 - val_accuracy: 0.7881 - val_loss: 0.7791\n",
            "Epoch 17/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.7503 - val_accuracy: 0.7950 - val_loss: 0.7628\n",
            "Epoch 18/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.7434 - val_accuracy: 0.7981 - val_loss: 0.7457\n",
            "Epoch 19/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.7141 - val_accuracy: 0.7881 - val_loss: 0.7455\n",
            "Epoch 20/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.6997 - val_accuracy: 0.7937 - val_loss: 0.7227\n",
            "Epoch 21/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.7073 - val_accuracy: 0.7912 - val_loss: 0.7306\n",
            "Epoch 22/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.6863 - val_accuracy: 0.8062 - val_loss: 0.6894\n",
            "Epoch 23/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.6709 - val_accuracy: 0.8087 - val_loss: 0.6805\n",
            "Epoch 24/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.6426 - val_accuracy: 0.8138 - val_loss: 0.6604\n",
            "Epoch 25/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.6606 - val_accuracy: 0.8087 - val_loss: 0.6630\n",
            "Epoch 26/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.6330 - val_accuracy: 0.8181 - val_loss: 0.6397\n",
            "Epoch 27/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.6253 - val_accuracy: 0.8131 - val_loss: 0.6324\n",
            "Epoch 28/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8204 - loss: 0.6222 - val_accuracy: 0.8206 - val_loss: 0.6157\n",
            "Epoch 29/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.5941 - val_accuracy: 0.8112 - val_loss: 0.6399\n",
            "Epoch 30/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.6004 - val_accuracy: 0.8313 - val_loss: 0.5974\n",
            "Epoch 31/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.5796 - val_accuracy: 0.8288 - val_loss: 0.5925\n",
            "Epoch 32/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.5779 - val_accuracy: 0.8175 - val_loss: 0.6099\n",
            "Epoch 33/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.5766 - val_accuracy: 0.8188 - val_loss: 0.5983\n",
            "Epoch 34/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8349 - loss: 0.5549 - val_accuracy: 0.8269 - val_loss: 0.5753\n",
            "Epoch 35/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.5537 - val_accuracy: 0.8263 - val_loss: 0.5818\n",
            "Epoch 36/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.5505 - val_accuracy: 0.8356 - val_loss: 0.5558\n",
            "Epoch 37/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.5357 - val_accuracy: 0.8344 - val_loss: 0.5625\n",
            "Epoch 38/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.5242 - val_accuracy: 0.8344 - val_loss: 0.5411\n",
            "Epoch 39/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.5413 - val_accuracy: 0.8350 - val_loss: 0.5387\n",
            "Epoch 40/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.5192 - val_accuracy: 0.8381 - val_loss: 0.5211\n",
            "Epoch 41/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.5131 - val_accuracy: 0.8438 - val_loss: 0.5216\n",
            "Epoch 42/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.4978 - val_accuracy: 0.8444 - val_loss: 0.5134\n",
            "Epoch 43/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.5059 - val_accuracy: 0.8462 - val_loss: 0.5067\n",
            "Epoch 44/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.4928 - val_accuracy: 0.8444 - val_loss: 0.4979\n",
            "Epoch 45/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.4904 - val_accuracy: 0.8456 - val_loss: 0.4921\n",
            "Epoch 46/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.4704 - val_accuracy: 0.8506 - val_loss: 0.4892\n",
            "Epoch 47/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.4693 - val_accuracy: 0.8462 - val_loss: 0.5063\n",
            "Epoch 48/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4738 - val_accuracy: 0.8469 - val_loss: 0.4898\n",
            "Epoch 49/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4656 - val_accuracy: 0.8531 - val_loss: 0.4669\n",
            "Epoch 50/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.4488 - val_accuracy: 0.8494 - val_loss: 0.4747\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.4677\n",
            "Test Loss: 0.4703\n",
            "Test Accuracy: 0.8595\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23, 19,  0, ..., 16, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify various hyperparameters, such as the number of hidden layers, neurons per hidden layer, activation functions, and learning rate, to observe their impact on model performance.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hyperparameters (now adjustable)\n",
        "num_hidden_layers = 2 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "neurons_per_layer = 64 #@param {type:\"slider\", min:16, max:128, step:16}\n",
        "activation_function = 'relu' #@param ['relu', 'sigmoid', 'tanh']\n",
        "learning_rate = 0.001 #@param {type:\"number\"}\n",
        "epochs = 50 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "batch_size = 32 #@param {type:\"slider\", min:16, max:64, step:16}\n",
        "\n",
        "# Load and preprocess data (same as before)\n",
        "# ... (Your existing data loading and preprocessing code)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Define the ANN model with adjustable hyperparameters\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons_per_layer, activation=activation_function, input_shape=(X.shape[1],)))\n",
        "\n",
        "for _ in range(num_hidden_layers - 1):  # Add more hidden layers if specified\n",
        "    model.add(Dense(neurons_per_layer, activation=activation_function))\n",
        "\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model with adjustable learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Split data (same as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model with adjustable hyperparameters\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SRnb53uuvg-8",
        "outputId": "26230981-fb4b-4632-acae-cedfa6a9dc38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │           \u001b[38;5;34m1,690\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,938\u001b[0m (27.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,938</span> (27.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,938\u001b[0m (27.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,938</span> (27.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1952 - loss: 2.9147 - val_accuracy: 0.5387 - val_loss: 1.7802\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5539 - loss: 1.6342 - val_accuracy: 0.6000 - val_loss: 1.4172\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 1.3562 - val_accuracy: 0.6556 - val_loss: 1.2465\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 1.2334 - val_accuracy: 0.6725 - val_loss: 1.1605\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 1.1142 - val_accuracy: 0.7038 - val_loss: 1.0859\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 1.0475 - val_accuracy: 0.7069 - val_loss: 1.0413\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.9763 - val_accuracy: 0.7237 - val_loss: 0.9880\n",
            "Epoch 8/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.9581 - val_accuracy: 0.7525 - val_loss: 0.9551\n",
            "Epoch 9/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7546 - loss: 0.9116 - val_accuracy: 0.7444 - val_loss: 0.9327\n",
            "Epoch 10/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.8830 - val_accuracy: 0.7681 - val_loss: 0.8974\n",
            "Epoch 11/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7690 - loss: 0.8394 - val_accuracy: 0.7663 - val_loss: 0.8584\n",
            "Epoch 12/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.8171 - val_accuracy: 0.7825 - val_loss: 0.8266\n",
            "Epoch 13/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.7876 - val_accuracy: 0.7631 - val_loss: 0.8154\n",
            "Epoch 14/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.7708 - val_accuracy: 0.7800 - val_loss: 0.7781\n",
            "Epoch 15/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.7262 - val_accuracy: 0.7844 - val_loss: 0.7610\n",
            "Epoch 16/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.7051 - val_accuracy: 0.7962 - val_loss: 0.7147\n",
            "Epoch 17/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.6723 - val_accuracy: 0.8087 - val_loss: 0.6897\n",
            "Epoch 18/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.6617 - val_accuracy: 0.8213 - val_loss: 0.6650\n",
            "Epoch 19/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.6380 - val_accuracy: 0.8238 - val_loss: 0.6578\n",
            "Epoch 20/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.6202 - val_accuracy: 0.8256 - val_loss: 0.6361\n",
            "Epoch 21/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.5946 - val_accuracy: 0.8181 - val_loss: 0.6273\n",
            "Epoch 22/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.5963 - val_accuracy: 0.8325 - val_loss: 0.5955\n",
            "Epoch 23/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.5738 - val_accuracy: 0.8400 - val_loss: 0.5743\n",
            "Epoch 24/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.5594 - val_accuracy: 0.8388 - val_loss: 0.5757\n",
            "Epoch 25/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.5271 - val_accuracy: 0.8462 - val_loss: 0.5536\n",
            "Epoch 26/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.5187 - val_accuracy: 0.8413 - val_loss: 0.5452\n",
            "Epoch 27/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.5060 - val_accuracy: 0.8431 - val_loss: 0.5405\n",
            "Epoch 28/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.4902 - val_accuracy: 0.8494 - val_loss: 0.5206\n",
            "Epoch 29/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.4806 - val_accuracy: 0.8575 - val_loss: 0.4994\n",
            "Epoch 30/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.4737 - val_accuracy: 0.8512 - val_loss: 0.5018\n",
            "Epoch 31/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.4747 - val_accuracy: 0.8519 - val_loss: 0.4878\n",
            "Epoch 32/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.4636 - val_accuracy: 0.8569 - val_loss: 0.4804\n",
            "Epoch 33/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.4496 - val_accuracy: 0.8606 - val_loss: 0.4701\n",
            "Epoch 34/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.4407 - val_accuracy: 0.8650 - val_loss: 0.4648\n",
            "Epoch 35/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.4300 - val_accuracy: 0.8631 - val_loss: 0.4545\n",
            "Epoch 36/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.4188 - val_accuracy: 0.8581 - val_loss: 0.4454\n",
            "Epoch 37/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.4181 - val_accuracy: 0.8744 - val_loss: 0.4349\n",
            "Epoch 38/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3946 - val_accuracy: 0.8731 - val_loss: 0.4315\n",
            "Epoch 39/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3934 - val_accuracy: 0.8675 - val_loss: 0.4299\n",
            "Epoch 40/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.3882 - val_accuracy: 0.8731 - val_loss: 0.4236\n",
            "Epoch 41/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3962 - val_accuracy: 0.8750 - val_loss: 0.4173\n",
            "Epoch 42/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.3784 - val_accuracy: 0.8781 - val_loss: 0.4080\n",
            "Epoch 43/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3755 - val_accuracy: 0.8750 - val_loss: 0.4187\n",
            "Epoch 44/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3703 - val_accuracy: 0.8781 - val_loss: 0.4015\n",
            "Epoch 45/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.3631 - val_accuracy: 0.8856 - val_loss: 0.3961\n",
            "Epoch 46/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.3580 - val_accuracy: 0.8781 - val_loss: 0.3873\n",
            "Epoch 47/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.3454 - val_accuracy: 0.8863 - val_loss: 0.3883\n",
            "Epoch 48/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.3672 - val_accuracy: 0.8938 - val_loss: 0.3779\n",
            "Epoch 49/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.3351 - val_accuracy: 0.8788 - val_loss: 0.3884\n",
            "Epoch 50/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.3390 - val_accuracy: 0.8763 - val_loss: 0.3862\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.3373\n",
            "Test Loss: 0.3485\n",
            "Test Accuracy: 0.8932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9ZMu-cwpP0",
        "outputId": "03221e37-e2c6-4747-f799-5c012e0f92e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kerastuner as kt\n",
        "\n",
        "# Load the dataset (assuming 'Alphabets_data.csv' is in the current directory)\n",
        "data = pd.read_csv('Alphabets_data.csv')\n",
        "\n",
        "# Data preprocessing (same as before)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numerical_cols = data.select_dtypes(include=['number']).columns\n",
        "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['letter'] = label_encoder.fit_transform(data['letter'])\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units_1', min_value=16, max_value=128, step=16),\n",
        "                    activation=hp.Choice('activation_1', values=['relu', 'sigmoid', 'tanh']),\n",
        "                    input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i+2}', min_value=16, max_value=128, step=16),\n",
        "                        activation=hp.Choice(f'activation_{i+2}', values=['relu', 'sigmoid', 'tanh'])))\n",
        "\n",
        "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=3,  # Adjust the number of trials as needed\n",
        "    executions_per_trial=3, # Run each trial multiple times for robustness\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units_1')}, in the second layer is {best_hps.get('units_2')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(X_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDNlZqTAybG7",
        "outputId": "5d29a0a9-03f2-4d30-f98b-11dc5dc5970e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 44s]\n",
            "val_accuracy: 0.5395833253860474\n",
            "\n",
            "Best val_accuracy So Far: 0.8735416531562805\n",
            "Total elapsed time: 00h 09m 16s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 112, in the second layer is 96 and the optimal learning rate for the optimizer\n",
            "is 0.0038554589940468283.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.9972 - val_accuracy: 0.2781 - val_loss: 2.1701\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3229 - loss: 2.0583 - val_accuracy: 0.5794 - val_loss: 1.4507\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.4480 - val_accuracy: 0.6181 - val_loss: 1.2228\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 1.1570 - val_accuracy: 0.7294 - val_loss: 0.9288\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.9194 - val_accuracy: 0.7663 - val_loss: 0.7975\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.8015 - val_accuracy: 0.7225 - val_loss: 0.9634\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.6361 - val_accuracy: 0.8356 - val_loss: 0.5631\n",
            "Epoch 8/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.5796 - val_accuracy: 0.8062 - val_loss: 0.6153\n",
            "Epoch 9/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.5246 - val_accuracy: 0.8594 - val_loss: 0.5087\n",
            "Epoch 10/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.4941 - val_accuracy: 0.8525 - val_loss: 0.4686\n",
            "Epoch 11/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.4172 - val_accuracy: 0.8631 - val_loss: 0.4275\n",
            "Epoch 12/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.4001 - val_accuracy: 0.8694 - val_loss: 0.4604\n",
            "Epoch 13/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8864 - loss: 0.3672 - val_accuracy: 0.8419 - val_loss: 0.5261\n",
            "Epoch 14/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.3637 - val_accuracy: 0.8944 - val_loss: 0.3459\n",
            "Epoch 15/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.3245 - val_accuracy: 0.8919 - val_loss: 0.3588\n",
            "Epoch 16/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2977 - val_accuracy: 0.9131 - val_loss: 0.3078\n",
            "Epoch 17/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2776 - val_accuracy: 0.8956 - val_loss: 0.3683\n",
            "Epoch 18/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.2969 - val_accuracy: 0.8938 - val_loss: 0.3775\n",
            "Epoch 19/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2914 - val_accuracy: 0.9125 - val_loss: 0.3189\n",
            "Epoch 20/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.2413 - val_accuracy: 0.9087 - val_loss: 0.3054\n",
            "Epoch 21/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2517 - val_accuracy: 0.9181 - val_loss: 0.2901\n",
            "Epoch 22/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2626 - val_accuracy: 0.9181 - val_loss: 0.2856\n",
            "Epoch 23/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.2395 - val_accuracy: 0.9219 - val_loss: 0.2652\n",
            "Epoch 24/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.2495 - val_accuracy: 0.8988 - val_loss: 0.3212\n",
            "Epoch 25/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2284 - val_accuracy: 0.9150 - val_loss: 0.2842\n",
            "Epoch 26/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.2094 - val_accuracy: 0.9056 - val_loss: 0.3426\n",
            "Epoch 27/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.2393 - val_accuracy: 0.9181 - val_loss: 0.2933\n",
            "Epoch 28/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.2086 - val_accuracy: 0.9019 - val_loss: 0.3056\n",
            "Epoch 29/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9312 - loss: 0.2193 - val_accuracy: 0.9038 - val_loss: 0.3411\n",
            "Epoch 30/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2694 - val_accuracy: 0.8994 - val_loss: 0.3801\n",
            "Epoch 31/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1945 - val_accuracy: 0.8744 - val_loss: 0.4319\n",
            "Epoch 32/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.2176 - val_accuracy: 0.9206 - val_loss: 0.2940\n",
            "Epoch 33/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.2044 - val_accuracy: 0.9112 - val_loss: 0.2834\n",
            "Epoch 34/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.2080 - val_accuracy: 0.9056 - val_loss: 0.3567\n",
            "Epoch 35/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1968 - val_accuracy: 0.9206 - val_loss: 0.2532\n",
            "Epoch 36/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9376 - loss: 0.2020 - val_accuracy: 0.9375 - val_loss: 0.2054\n",
            "Epoch 37/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1750 - val_accuracy: 0.9219 - val_loss: 0.2925\n",
            "Epoch 38/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1978 - val_accuracy: 0.9187 - val_loss: 0.3054\n",
            "Epoch 39/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.2149 - val_accuracy: 0.9394 - val_loss: 0.2050\n",
            "Epoch 40/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1764 - val_accuracy: 0.9275 - val_loss: 0.2951\n",
            "Epoch 41/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1866 - val_accuracy: 0.9194 - val_loss: 0.3261\n",
            "Epoch 42/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.2032 - val_accuracy: 0.9144 - val_loss: 0.2713\n",
            "Epoch 43/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1688 - val_accuracy: 0.9044 - val_loss: 0.3314\n",
            "Epoch 44/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.2215 - val_accuracy: 0.9287 - val_loss: 0.2788\n",
            "Epoch 45/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1716 - val_accuracy: 0.9087 - val_loss: 0.3356\n",
            "Epoch 46/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.2317 - val_accuracy: 0.9362 - val_loss: 0.2512\n",
            "Epoch 47/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1781 - val_accuracy: 0.9300 - val_loss: 0.2816\n",
            "Epoch 48/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1886 - val_accuracy: 0.9388 - val_loss: 0.2190\n",
            "Epoch 49/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1887 - val_accuracy: 0.9425 - val_loss: 0.2251\n",
            "Epoch 50/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1807 - val_accuracy: 0.9144 - val_loss: 0.3033\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3781\n",
            "Test Loss: 0.3858\n",
            "Test Accuracy: 0.9032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_test, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAvgY9do0HfD",
        "outputId": "ed9dbcdd-867b-4956-ab80-7e990d0c56e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.3781\n",
            "Test Loss: 0.3858\n",
            "Test Accuracy: 0.9032\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       149\n",
            "           1       0.83      0.93      0.88       153\n",
            "           2       0.89      0.80      0.84       137\n",
            "           3       0.87      0.89      0.88       156\n",
            "           4       0.88      0.85      0.87       141\n",
            "           5       0.91      0.89      0.90       140\n",
            "           6       0.73      0.82      0.77       160\n",
            "           7       0.90      0.78      0.84       144\n",
            "           8       0.86      0.99      0.92       146\n",
            "           9       0.96      0.91      0.93       149\n",
            "          10       0.84      0.86      0.85       130\n",
            "          11       0.99      0.92      0.95       155\n",
            "          12       1.00      0.91      0.95       168\n",
            "          13       0.93      0.93      0.93       151\n",
            "          14       0.91      0.90      0.90       145\n",
            "          15       0.92      0.95      0.93       173\n",
            "          16       0.95      0.86      0.90       166\n",
            "          17       0.91      0.81      0.85       160\n",
            "          18       0.92      0.92      0.92       171\n",
            "          19       0.94      0.92      0.93       163\n",
            "          20       0.93      0.94      0.94       183\n",
            "          21       0.90      0.89      0.90       158\n",
            "          22       0.97      0.95      0.96       148\n",
            "          23       0.89      0.92      0.90       154\n",
            "          24       0.89      0.98      0.93       168\n",
            "          25       0.86      0.97      0.91       132\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.90      0.90      0.90      4000\n",
            "weighted avg       0.91      0.90      0.90      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss_default, accuracy_default = model.evaluate(X_test, y_test)\n",
        "print(f\"Default Model - Test Loss: {loss_default:.4f}\")\n",
        "print(f\"Default Model - Test Accuracy: {accuracy_default:.4f}\")\n",
        "\n",
        "# ... (Your hyperparameter tuning code)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "loss_tuned, accuracy_tuned = model.evaluate(X_test, y_test)\n",
        "print(f\"Tuned Model - Test Loss: {loss_tuned:.4f}\")\n",
        "print(f\"Tuned Model - Test Accuracy: {accuracy_tuned:.4f}\")\n",
        "\n",
        "# Compare performance\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"  Accuracy Improvement: {accuracy_tuned - accuracy_default:.4f}\")\n",
        "print(f\"  Loss Reduction: {loss_default - loss_tuned:.4f}\")\n",
        "\n",
        "# Discussion\n",
        "print(\"\\nDiscussion:\")\n",
        "if accuracy_tuned > accuracy_default:\n",
        "    print(\"  Hyperparameter tuning resulted in an improved accuracy. This indicates that the optimized hyperparameters (number of layers, neurons per layer, activation function, learning rate, epochs, batch size) better fit the data, leading to a model that generalizes better to unseen data. The reduction in loss further supports the improvement.\")\n",
        "elif accuracy_tuned < accuracy_default:\n",
        "    print(\"  Hyperparameter tuning did not improve the accuracy and might have even made it worse. This could be due to several reasons, including:\")\n",
        "    print(\"    * Insufficient search space or number of trials in the hyperparameter tuning process.\")\n",
        "    print(\"    * The default hyperparameters already performed well, and there was limited room for improvement.\")\n",
        "    print(\"    * Overfitting to the validation data during the search process.\")\n",
        "    print(\"  Further investigation and tuning with a wider range of hyperparameters is advised.\")\n",
        "else:\n",
        "    print(\"  Hyperparameter tuning resulted in similar accuracy to the default settings. The optimized hyperparameters may have marginally improved performance, but not significantly enough to affect the accuracy metric.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlTSUAmS1FkT",
        "outputId": "4ad23328-ad7b-409d-9bf5-6602e29461a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3781\n",
            "Default Model - Test Loss: 0.3858\n",
            "Default Model - Test Accuracy: 0.9032\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.3781\n",
            "Tuned Model - Test Loss: 0.3858\n",
            "Tuned Model - Test Accuracy: 0.9032\n",
            "\n",
            "Performance Comparison:\n",
            "  Accuracy Improvement: 0.0000\n",
            "  Loss Reduction: 0.0000\n",
            "\n",
            "Discussion:\n",
            "  Hyperparameter tuning resulted in similar accuracy to the default settings. The optimized hyperparameters may have marginally improved performance, but not significantly enough to affect the accuracy metric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The code trains and evaluates an Artificial Neural Network (ANN) model for classifying alphabets from a dataset named 'Alphabets_data.csv'.\n",
        "The process involves several key steps: data preprocessing (handling missing values using imputation, normalization, and label encoding),\n",
        "model definition (a sequential ANN with adjustable hyperparameters like number of layers, neurons, and activation function),\n",
        "hyperparameter tuning using Keras Tuner to find optimal settings for improved performance, model training and evaluation, and\n",
        "finally a comparison between the performance of the default model and the tuned model.\n",
        "The code concludes by presenting a discussion of the performance comparison, analyzing whether hyperparameter tuning led\n",
        "to an improvement in the model’s accuracy and loss, or if further adjustments are needed.\n",
        "A classification report provides a detailed performance summary including precision, recall, F1-score for each alphabet class.\n",
        "'''"
      ],
      "metadata": {
        "id": "ZlvRinLi1Yob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}